{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training Fair XGBoost Model ===\n",
      "Overall Performance Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      1.00      0.69      1153\n",
      "           1       0.00      0.00      0.00      1012\n",
      "\n",
      "    accuracy                           0.53      2165\n",
      "   macro avg       0.27      0.50      0.35      2165\n",
      "weighted avg       0.28      0.53      0.37      2165\n",
      "\n",
      "\n",
      "Fairness Metrics:\n",
      "Disparate Impact: 1.662\n",
      "Statistical Parity Difference: 0.203\n",
      "Equal Opportunity Difference: 0.000\n",
      "Average Odds Difference: 0.000\n",
      "\n",
      "=== Training Regular XGBoost Model ===\n",
      "Overall Performance Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.73      0.72      1153\n",
      "           1       0.68      0.66      0.67      1012\n",
      "\n",
      "    accuracy                           0.69      2165\n",
      "   macro avg       0.69      0.69      0.69      2165\n",
      "weighted avg       0.69      0.69      0.69      2165\n",
      "\n",
      "\n",
      "Fairness Metrics:\n",
      "Disparate Impact: 1.662\n",
      "Statistical Parity Difference: 0.203\n",
      "Equal Opportunity Difference: 0.230\n",
      "Average Odds Difference: 0.215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fsd_n\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [17:23:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\fsd_n\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\fsd_n\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\fsd_n\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import xgboost as xgb\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "\n",
    "class ImpactParityXGBoostClassifier:\n",
    "    def __init__(self, fairness_regularizer_weight=0.3, impact_threshold=0.9, base_estimator_params=None):\n",
    "        self.fairness_weight = fairness_regularizer_weight\n",
    "        self.impact_threshold = impact_threshold\n",
    "        self.base_params = base_estimator_params or {\n",
    "            'max_depth': 3,\n",
    "            'learning_rate': 0.1,\n",
    "            'n_estimators': 200,\n",
    "            'objective': 'binary:logistic'\n",
    "        }\n",
    "        self.model = None\n",
    "        self.protected_attributes = None\n",
    "        \n",
    "    def _compute_impact_parity_penalty(self, y_pred):\n",
    "        y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "        privileged_mask = self.protected_attributes == 1\n",
    "        unprivileged_mask = self.protected_attributes == 0\n",
    "        \n",
    "        priv_positive_rate = np.mean(y_pred_binary[privileged_mask])\n",
    "        unpriv_positive_rate = np.mean(y_pred_binary[unprivileged_mask])\n",
    "        \n",
    "        eps = 1e-10\n",
    "        impact_ratio = unpriv_positive_rate / (priv_positive_rate + eps)\n",
    "        \n",
    "        if impact_ratio < self.impact_threshold:\n",
    "            penalty = (self.impact_threshold - impact_ratio) ** 2\n",
    "        else:\n",
    "            penalty = abs(1.0 - impact_ratio)\n",
    "            \n",
    "        return penalty\n",
    "        \n",
    "    def _fair_objective(self, y_pred, dtrain):\n",
    "        y_true = dtrain.get_label()\n",
    "        grad = y_pred - y_true\n",
    "        hess = y_pred * (1.0 - y_pred)\n",
    "        fairness_penalty = self._compute_impact_parity_penalty(y_pred)\n",
    "        grad += self.fairness_weight * fairness_penalty\n",
    "        return grad, hess\n",
    "    \n",
    "    def fit(self, X, y, protected_attributes):\n",
    "        self.protected_attributes = protected_attributes\n",
    "        dtrain = xgb.DMatrix(X, label=y)\n",
    "        params = self.base_params.copy()\n",
    "        params['objective'] = None\n",
    "        self.model = xgb.train(params, dtrain, obj=self._fair_objective)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model needs to be fitted first\")\n",
    "        dtest = xgb.DMatrix(X)\n",
    "        return (self.model.predict(dtest) > 0.5).astype(int)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model needs to be fitted first\")\n",
    "        dtest = xgb.DMatrix(X)\n",
    "        return self.model.predict(dtest)\n",
    "\n",
    "def create_aif_dataset(X, y, protected_attribute_name, protected_values):\n",
    "    df = pd.DataFrame(X.copy())\n",
    "    df['label'] = y\n",
    "    df[protected_attribute_name] = protected_values\n",
    "    \n",
    "    return BinaryLabelDataset(\n",
    "        df=df,\n",
    "        label_names=['label'],\n",
    "        protected_attribute_names=[protected_attribute_name],\n",
    "        favorable_label=1.0,\n",
    "        unfavorable_label=0.0\n",
    "    )\n",
    "\n",
    "def evaluate_detailed_metrics(model, X_test, y_test, protected_test, group_name=\"sex_Male\"):\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    print(\"Overall Performance Metrics:\")\n",
    "    print(classification_report(y_test, predictions))\n",
    "    \n",
    "    dataset_true = create_aif_dataset(X_test, y_test, group_name, protected_test)\n",
    "    dataset_pred = create_aif_dataset(X_test, predictions, group_name, protected_test)\n",
    "    \n",
    "    privileged_groups = [{group_name: 1}]\n",
    "    unprivileged_groups = [{group_name: 0}]\n",
    "    \n",
    "    dataset_metrics = BinaryLabelDatasetMetric(\n",
    "        dataset_true,\n",
    "        unprivileged_groups=unprivileged_groups,\n",
    "        privileged_groups=privileged_groups\n",
    "    )\n",
    "    \n",
    "    class_metrics = ClassificationMetric(\n",
    "        dataset_true,\n",
    "        dataset_pred,\n",
    "        unprivileged_groups=unprivileged_groups,\n",
    "        privileged_groups=privileged_groups\n",
    "    )\n",
    "    \n",
    "    print(\"\\nFairness Metrics:\")\n",
    "    print(f\"Disparate Impact: {dataset_metrics.disparate_impact():.3f}\")\n",
    "    print(f\"Statistical Parity Difference: {dataset_metrics.statistical_parity_difference():.3f}\")\n",
    "    print(f\"Equal Opportunity Difference: {class_metrics.equal_opportunity_difference():.3f}\")\n",
    "    print(f\"Average Odds Difference: {class_metrics.average_odds_difference():.3f}\")\n",
    "\n",
    "def prepare_data(filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    use_df = df[['sex','age_cat','race',\n",
    "                'juv_fel_count','juv_misd_count','juv_other_count','priors_count',\n",
    "                'c_charge_degree', 'decile_score', 'v_decile_score', 'score_text', \n",
    "                'v_score_text', 'is_recid', 'is_violent_recid']]\n",
    "\n",
    "    categorical_columns = ['sex', 'age_cat', 'c_charge_degree']\n",
    "    encoded_df = pd.get_dummies(use_df, columns=categorical_columns, drop_first=True)\n",
    "    encoded_df = pd.get_dummies(encoded_df, columns=['race'], drop_first=False)\n",
    "\n",
    "    score_mapping = {'Low': 0, 'Medium': 1, 'High': 2}\n",
    "    encoded_df['score_text'] = encoded_df['score_text'].map(score_mapping)\n",
    "    encoded_df['v_score_text'] = encoded_df['v_score_text'].map(score_mapping)\n",
    "\n",
    "    X = encoded_df.drop(columns=['decile_score', 'v_decile_score', 'score_text', \n",
    "                               'v_score_text', 'is_recid', 'is_violent_recid'])\n",
    "    y = encoded_df['is_recid']\n",
    "\n",
    "    # For gender bias\n",
    "    # protected_attributes = encoded_df['sex_Male'].values\n",
    "\n",
    "    # For age bias\n",
    "    protected_attributes = encoded_df['age_cat_Greater than 45'].values\n",
    "\n",
    "    # For race bias\n",
    "    # protected_attributes = encoded_df['race_African-American'].values\n",
    "\n",
    "    return train_test_split(X, y, protected_attributes, test_size=0.3, random_state=42)\n",
    "\n",
    "def main():\n",
    "    X_train, X_test, y_train, y_test, protected_train, protected_test = prepare_data('compas-scores-two-years.csv')\n",
    "\n",
    "    print(\"\\n=== Training Fair XGBoost Model ===\")\n",
    "    fair_xgb = ImpactParityXGBoostClassifier(\n",
    "        fairness_regularizer_weight=0.3,\n",
    "        impact_threshold=0.9,\n",
    "        base_estimator_params={\n",
    "            'max_depth': 3,\n",
    "            'learning_rate': 0.1,\n",
    "            'n_estimators': 200,\n",
    "            'random_state': 42\n",
    "        }\n",
    "    )\n",
    "    fair_xgb.fit(X_train, y_train, protected_train)\n",
    "    evaluate_detailed_metrics(fair_xgb, X_test, y_test, protected_test)\n",
    "\n",
    "    print(\"\\n=== Training Regular XGBoost Model ===\")\n",
    "    regular_xgb = xgb.XGBClassifier(\n",
    "        max_depth=3,\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=200,\n",
    "        random_state=42,\n",
    "        objective='binary:logistic'\n",
    "    )\n",
    "    regular_xgb.fit(X_train, y_train)\n",
    "    evaluate_detailed_metrics(regular_xgb, X_test, y_test, protected_test)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
